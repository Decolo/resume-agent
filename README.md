# Resume Agent

An AI-powered resume modification agent built on open-source LLM agent technology. This project demonstrates how to build a practical agent with tools that connect LLMs to local filesystem operations.

## Features

- ğŸ“„ **Multi-format Support**: Parse and generate resumes in PDF, DOCX, Markdown, JSON, HTML
- ğŸ”§ **Tool-based Architecture**: Modular tools for file operations, resume parsing, and generation
- ğŸ¤– **Multiple LLM Backends**: Gemini by default, with an OpenAI-compatible client available
- ğŸ’¬ **Interactive CLI**: Rich command-line interface with conversation history
- ğŸ“ **Resume Expert Knowledge**: Built-in expertise for ATS optimization, action verbs, and best practices

## ğŸ“š Documentation

Complete documentation is available in the `/docs` directory:

- **[Environment Setup](./docs/setup/environment-setup.md)** - API keys and local config
- **[Session Persistence](./docs/sessions/session-persistence.md)** - Save and restore sessions
- **[Export History](./docs/usage/export-history.md)** - Save or copy conversation history
- **[Architecture Overview](./.claude/CLAUDE.md)** - System design and components (Claude Code instructions)
- **[Phase 1 Improvements](./docs/architecture/phase1-improvements.md)** - Technical improvements
- **[API Reference](./docs/api-reference/phase1-quick-reference.md)** - Code examples and API usage
- **Examples Folder** - Sample resumes and workspaces live in `./examples/`

## Quick Start

### 1. Install Dependencies

```bash
cd resume-agent

# Using uv (recommended)
uv sync

# Or using pip
pip install -e .
```

### 2. Configure API Key

Edit `config/config.local.yaml` (default) or set an environment variable:

```bash
export GEMINI_API_KEY="your-gemini-api-key"
```

### 3. Run the Agent

```bash
# Interactive mode (recommended)
uv run resume-agent --workspace ./examples/my_resume

# Or with Python
uv run python -m resume_agent.cli

# Single prompt mode
uv run resume-agent --prompt "Parse my resume and analyze it"
```

For detailed instructions, see [Documentation Index](./docs/README.md).

## Usage Examples

### Analyze a Resume
```
ğŸ“ You: Parse my resume from examples/sample_resumes/sample_resume.md and give me feedback
```

### Improve Work Experience
```
ğŸ“ You: Improve the bullet points in my experience section with stronger action verbs and quantifiable metrics
```

### Tailor for a Job
```
ğŸ“ You: Tailor my resume for a Senior Backend Engineer position at Google, focusing on distributed systems experience
```

### Convert Format
```
ğŸ“ You: Convert my resume to a modern HTML format and save it as output/resume.html
```

## Project Structure

```
resume-agent/
â”œâ”€â”€ resume_agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py          # Core agent loop
â”‚   â”œâ”€â”€ llm.py            # Gemini LLM client
â”‚   â”œâ”€â”€ llm_openai.py     # OpenAI-compatible LLM client
â”‚   â”œâ”€â”€ cli.py            # Command-line interface
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ base.py           # Base tool class
â”‚   â”‚   â”œâ”€â”€ file_tool.py      # File read/write/list
â”‚   â”‚   â”œâ”€â”€ bash_tool.py      # Shell command execution
â”‚   â”‚   â”œâ”€â”€ resume_parser.py  # PDF/DOCX/MD parsing
â”‚   â”‚   â””â”€â”€ resume_writer.py  # Multi-format output
â”‚   â””â”€â”€ skills/
â”‚       â””â”€â”€ resume_expert.py  # System prompt
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.local.yaml # Local config (default, keep secrets here)
â”‚   â””â”€â”€ config.yaml       # Optional shared defaults
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ sample_resumes/   # Example resumes
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## Tools

| Tool | Description |
|------|-------------|
| `file_read` | Read text file contents |
| `file_write` | Write content to files |
| `file_list` | List directory contents |
| `bash` | Execute shell commands |
| `resume_parse` | Parse PDF/DOCX/MD/JSON resumes |
| `resume_write` | Generate MD/TXT/JSON/HTML output |

## Architecture

This agent follows the standard **LLM Agent Loop**:

```
User Input â†’ LLM (with tools) â†’ Tool Calls â†’ Tool Results â†’ LLM â†’ ... â†’ Final Response
```

The key components are:

1. **LLM Client** (`llm.py`, `llm_openai.py`): Gemini client plus OpenAI-compatible adapter
2. **Tools** (`tools/`): Connect the LLM to local system capabilities
3. **Agent Loop** (`agent.py`): Orchestrates the conversation and tool execution
4. **System Prompt** (`skills/`): Provides domain expertise

## Supported LLM Providers

- **Google Gemini** is the default (via `resume_agent/llm.py`).
- **OpenAI-compatible endpoints** can be used via `resume_agent/llm_openai.py` when wired in.

## License

MIT License
